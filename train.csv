actor_entropy,actor_loss,actor_target_entropy,alpha_loss,alpha_value,batch_reward,critic_loss,duration,episode,episode_reward,step
0.33072951152211144,-1.9975277757833874,-1.0,0.1301729485156044,0.09818558807856481,1.1803394203186035,5.832986974716187,30.804609775543213,9.0,173.19844219448078,9000
0.5204694146110166,-3.5209185000388854,-1.0,0.1403965561860992,0.09227445523921901,1.207578567504883,2.0020991773605346,29.952145099639893,10.0,190.7788161891014,10000
0.4324983959160154,-3.870157132073054,-1.0,0.12471638809120844,0.08705540689529549,1.1952956533432006,1.7796229963302612,30.17655873298645,11.0,150.49527882982252,11000
